/**
 * AiProvider - AI æä¾›è€…æ ¸å¿ƒç±»
 * å®Œå…¨å‚è€ƒ Cherry Studio aiCore/legacy/index.ts å®ç°
 * 
 * èŒè´£ï¼š
 * 1. æ ¹æ® Provider åˆ›å»ºå¯¹åº”çš„ ApiClient
 * 2. æ„å»ºå’Œç®¡ç†ä¸­é—´ä»¶é“¾
 * 3. æ‰§è¡Œ completions è¯·æ±‚
 * 4. å¤„ç†æµå¼å“åº”
 */

import { ApiClientFactory, initializeDefaultClients } from './clients';
import type { BaseApiClient } from './clients/base';
import type { Provider } from './types/provider';
import type { Chunk } from './types/chunk';
import { ChunkType } from './types/chunk';
import type { SdkModel } from './types/sdk';
import type { Model } from '../types';

// å¯¼å…¥é€‚é…å™¨
import { OpenAIToAiSdkAdapter } from './adapters/OpenAIToAiSdkAdapter';
import { AiSdkToChunkAdapter } from './adapters/AiSdkToChunkAdapter';
import type { MCPTool as AdapterMCPTool } from './adapters/ToolCallChunkHandler';

// å¯¼å…¥ç°æœ‰çš„ MCP æç¤ºè¯æ„å»ºå‡½æ•°
import { buildSystemPrompt } from '../utils/mcpPrompt';
// å¯¼å…¥ MCP å·¥å…·è°ƒç”¨ç›¸å…³å‡½æ•°
import { parseToolUse, parseAndCallTools, hasToolUseTags } from '../utils/mcpToolParser';

// å¯¼å…¥æ–°çš„ä¸­é—´ä»¶ç³»ç»Ÿ
import {
  CompletionsMiddlewareBuilder,
  applyCompletionsMiddlewares,
  MiddlewareRegistry,
  type CompletionsParams as MiddlewareCompletionsParams,
} from './middleware';

// å›¾ç‰‡ç”Ÿæˆæ¨¡å‹åˆ¤æ–­
import { MIDDLEWARE_NAME as FinalChunkConsumerMiddlewareName } from './middleware/common/FinalChunkConsumerMiddleware';
import { MIDDLEWARE_NAME as ErrorHandlerMiddlewareName } from './middleware/common/ErrorHandlerMiddleware';
import { MIDDLEWARE_NAME as AbortHandlerMiddlewareName } from './middleware/common/AbortHandlerMiddleware';
import { MIDDLEWARE_NAME as ImageGenerationMiddlewareName } from './middleware/feat/ImageGenerationMiddleware';

// ==================== Types ====================

/**
 * Completions è¯·æ±‚å‚æ•°
 */
export interface CompletionsParams {
  /** è°ƒç”¨ç±»å‹ */
  callType: 'chat' | 'check' | 'translate' | 'summary' | 'generate' | 'search' | 'test';
  /** æ¶ˆæ¯å†…å®¹ï¼ˆå¯ä»¥æ˜¯æ¶ˆæ¯æ•°ç»„æˆ–å­—ç¬¦ä¸²ï¼‰*/
  messages: Message[] | string;
  /** åŠ©æ‰‹é…ç½® */
  assistant: Assistant;
  /** æ˜¯å¦æµå¼è¾“å‡º */
  streamOutput?: boolean;
  /** ä¸»é¢˜ID */
  topicId?: string;
  /** MCPå·¥å…·åˆ—è¡¨ */
  mcpTools?: MCPTool[];
  /** MCP æ¨¡å¼ï¼šprompt=æç¤ºè¯æ³¨å…¥, function=å‡½æ•°è°ƒç”¨ */
  mcpMode?: 'prompt' | 'function';
  /** æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢ */
  enableWebSearch?: boolean;
  /** æ˜¯å¦å¯ç”¨å›¾ç‰‡ç”Ÿæˆ */
  enableGenerateImage?: boolean;
  /** æœ€å¤§ tokens */
  maxTokens?: number;
  /** æ˜¯å¦åº”è¯¥æŠ›å‡ºé”™è¯¯ */
  shouldThrow?: boolean;
  /** Chunk å›è°ƒ */
  onChunk?: (chunk: Chunk) => void;
  /** ä¸­æ–­ä¿¡å· */
  abortSignal?: AbortSignal;
}

/**
 * Completions ç»“æœ
 */
export interface CompletionsResult {
  /** è·å–æ–‡æœ¬å†…å®¹ */
  getText: () => string;
  /** è·å–æ¨ç†å†…å®¹ */
  getReasoning: () => string | undefined;
  /** è·å–åŸå§‹è¾“å‡º */
  rawOutput?: unknown;
  /** ä½¿ç”¨ç»Ÿè®¡ */
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * æ¶ˆæ¯ç±»å‹
 */
export interface Message {
  id?: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  topicId?: string;
  [key: string]: unknown;
}

/**
 * åŠ©æ‰‹é…ç½®
 */
export interface Assistant {
  id: string;
  name?: string;
  prompt?: string;
  model?: Model;
  settings?: {
    temperature?: number;
    topP?: number;
    maxTokens?: number;
    streamOutput?: boolean;
    reasoning_effort?: 'low' | 'medium' | 'high';
    [key: string]: unknown;
  };
  mcpServers?: { id: string }[];
  [key: string]: unknown;
}

/**
 * MCP å·¥å…·
 */
export interface MCPTool {
  id?: string;
  name: string;
  description?: string;
  inputSchema?: unknown;
  serverId?: string;
  [key: string]: unknown;
}

/**
 * å›¾ç‰‡ç”Ÿæˆå‚æ•°
 */
export interface GenerateImageParams {
  model: string;
  prompt: string;
  negativePrompt?: string;
  imageSize?: string;
  batchSize?: number;
  seed?: string;
  numInferenceSteps?: number;
  guidanceScale?: number;
  signal?: AbortSignal;
  promptEnhancement?: boolean;
}

// ==================== AiProvider Class ====================

/**
 * AI æä¾›è€…ç±»
 * æ ¸å¿ƒå…¥å£ï¼Œè´Ÿè´£åˆ›å»ºå®¢æˆ·ç«¯ã€æ„å»ºä¸­é—´ä»¶ã€æ‰§è¡Œè¯·æ±‚
 */
export default class AiProvider {
  private apiClient: BaseApiClient;
  private provider: Provider;
  private initialized = false;

  constructor(provider: Provider) {
    this.provider = provider;
    // å»¶è¿Ÿåˆå§‹åŒ–å®¢æˆ·ç«¯
    this.apiClient = null as unknown as BaseApiClient;
  }

  /**
   * ç¡®ä¿å®¢æˆ·ç«¯å·²åˆå§‹åŒ–
   */
  private async ensureInitialized(): Promise<void> {
    if (this.initialized) return;
    
    await initializeDefaultClients();
    this.apiClient = ApiClientFactory.create(this.provider);
    this.initialized = true;
    
    console.log(`[AiProvider] åˆå§‹åŒ–å®Œæˆ - Provider: ${this.provider.id}, Type: ${this.provider.type}`);
  }

  /**
   * æ‰§è¡Œ Completions è¯·æ±‚
   * ä½¿ç”¨é€‚é…å™¨é“¾å¤„ç†æµå¼å“åº”ï¼ˆå‚è€ƒ Cherry Studio æ¶æ„ï¼‰
   * 
   * æµç¨‹ï¼šOpenAIClient â†’ OpenAIToAiSdkAdapter â†’ AiSdkToChunkAdapter â†’ Chunk å›è°ƒ
   */
  public async completions(
    params: CompletionsParams,
    options?: { signal?: AbortSignal; timeout?: number }
  ): Promise<CompletionsResult> {
    await this.ensureInitialized();

    const {
      messages,
      assistant,
      streamOutput = true,
      onChunk,
      mcpTools,
    } = params;

    const model = assistant.model;
    if (!model) {
      throw new Error('Model is required');
    }

    console.log(`[AiProvider] completions - Model: ${model.id}, Stream: ${streamOutput}`);

    // ç”¨äºå­˜å‚¨æœ€ç»ˆç»“æœ
    let finalText = '';
    let finalReasoning = '';
    let usage: CompletionsResult['usage'];

    try {
      // 1. è½¬æ¢æ¶ˆæ¯æ ¼å¼
      const sdkMessages = this.transformMessages(messages, assistant, mcpTools, params.mcpMode);

      // 2. æ„å»º SDK è¯·æ±‚å‚æ•°
      const transformer = this.apiClient.getRequestTransformer();
      const sdkPayload = transformer.transform({
        // ä¼ é€’å®Œæ•´æ¶ˆæ¯å¯¹è±¡ï¼ŒåŒ…æ‹¬ images ç­‰å±æ€§
        messages: sdkMessages.map((m, i) => ({
          ...m,
          id: m.id || `msg-${i}`,
        })),
        assistant,
        mcpTools: params.mcpMode === 'prompt' ? [] : mcpTools?.map(t => ({
          ...t,
          serverName: t.serverId || 'unknown',
        })) as any,
        enableToolUse: params.mcpMode === 'prompt' ? false : !!mcpTools?.length,
        mcpMode: params.mcpMode,
      });
      
      (sdkPayload as any).stream = streamOutput;

      // 3. å‘é€ LLM_RESPONSE_CREATEDï¼ˆé€‚é…å™¨å†…éƒ¨ä¸ä¼šå‘é€è¿™ä¸ªï¼‰
      if (onChunk) {
        await onChunk({ type: ChunkType.LLM_RESPONSE_CREATED });
      }

      // 4. æ‰§è¡Œè¯·æ±‚
      const rawStream = await this.apiClient.createCompletions(
        sdkPayload as any,
        { signal: options?.signal || params.abortSignal }
      );

      // 5. åˆ›å»º onChunk å›è°ƒ
      const chunkCallback = (chunk: Chunk) => {
        // æ”¶é›†ç»“æœï¼ˆä½¿ç”¨ç´¯ç§¯çš„æ–‡æœ¬ï¼‰
        if (chunk.type === ChunkType.TEXT_DELTA) {
          finalText += (chunk as any).text || '';
        }
        if (chunk.type === ChunkType.THINKING_DELTA) {
          finalReasoning += (chunk as any).text || '';
        }
        if (chunk.type === ChunkType.LLM_RESPONSE_COMPLETE && (chunk as any).response?.usage) {
          usage = (chunk as any).response.usage;
        }
        
        // è½¬å‘ç»™å¤–éƒ¨å›è°ƒ
        if (onChunk) {
          onChunk(chunk);
        }
      };

      console.log('[AiProvider] å¼€å§‹å¤„ç†æµ..., Provider:', this.provider.type);

      // 6. æ ¹æ® provider ç±»å‹é€‰æ‹©ä¸åŒçš„æµå¤„ç†æ–¹å¼
      const providerType = this.provider.type?.toLowerCase() || '';
      
      if (providerType === 'gemini' || providerType === 'google') {
        // Gemini ä¸“ç”¨å¤„ç†ï¼ˆå¯¹æ ‡ Cherry Studioï¼‰
        await this.processGeminiStream(rawStream as AsyncIterable<any>, chunkCallback);
      } else {
        // OpenAI å…¼å®¹æ ¼å¼ â†’ AI SDK æ ¼å¼ â†’ Chunk äº‹ä»¶
        const openAIAdapter = new OpenAIToAiSdkAdapter();
        const aiSdkResult = await openAIAdapter.convertToAiSdkStream(rawStream as AsyncIterable<any>);
        
        const chunkAdapter = new AiSdkToChunkAdapter(
          chunkCallback,
          mcpTools as AdapterMCPTool[],
          true,
          params.enableWebSearch
        );
        
        await chunkAdapter.processStream(aiSdkResult);
      }

      // 6. æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆæç¤ºè¯æ³¨å…¥æ¨¡å¼çš„å¤šè½®å·¥å…·è°ƒç”¨ï¼‰
      if (params.mcpMode === 'prompt' && mcpTools && mcpTools.length > 0) {
        const hasTools = hasToolUseTags(finalText, mcpTools as any);
        
        if (hasTools) {
          console.log(`[AiProvider] ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œå¼€å§‹æ‰§è¡Œ...`);
          
          const toolResponses = parseToolUse(finalText, mcpTools as any);
          
          if (toolResponses.length > 0) {
            console.log(`[AiProvider] è§£æå‡º ${toolResponses.length} ä¸ªå·¥å…·è°ƒç”¨`);
            
            // æ‰§è¡Œå·¥å…·è°ƒç”¨
            const toolResults = await parseAndCallTools(toolResponses, mcpTools as any, onChunk);
            
            // æ ¼å¼åŒ–å·¥å…·ç»“æœ
            const toolResultsText = toolResults.map((result, index) => {
              const toolResponse = toolResponses[index];
              if (result.isError) {
                return `<tool_use_result>\n  <name>${toolResponse.tool.name}</name>\n  <error>${result.content.map(c => c.text).join('\n')}</error>\n</tool_use_result>`;
              } else {
                return `<tool_use_result>\n  <name>${toolResponse.tool.name}</name>\n  <result>${JSON.stringify(result.content)}</result>\n</tool_use_result>`;
              }
            }).join('\n\n');
            
            console.log(`[AiProvider] ğŸ”„ é€’å½’è°ƒç”¨ LLMï¼Œä¼ é€’å·¥å…·ç»“æœ...`);
            
            // æ„å»ºé€’å½’æ¶ˆæ¯
            const originalMessages = Array.isArray(messages) ? messages : [{ role: 'user' as const, content: messages }];
            const newMessages: Message[] = [
              ...originalMessages,
              { role: 'assistant', content: finalText },
              { role: 'user', content: toolResultsText }
            ];
            
            // é€’å½’è°ƒç”¨ï¼ˆæœ€å¤š 5 æ¬¡ï¼‰
            const recursionDepth = (params as any)._recursionDepth || 0;
            if (recursionDepth < 5) {
              const recursiveResult = await this.completions({
                ...params,
                messages: newMessages,
                _recursionDepth: recursionDepth + 1,
              } as any, options);
              
              return {
                getText: () => recursiveResult.getText(),
                getReasoning: () => recursiveResult.getReasoning(),
                usage: recursiveResult.usage || usage,
              };
            } else {
              console.warn(`[AiProvider] âš ï¸ è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦ï¼Œåœæ­¢å·¥å…·è°ƒç”¨`);
            }
          }
        }
      }

      console.log(`[AiProvider] completions å®Œæˆ - æ–‡æœ¬: ${finalText.length}å­—, æ¨ç†: ${finalReasoning.length}å­—`);

      return {
        getText: () => finalText,
        getReasoning: () => finalReasoning || undefined,
        usage,
      };
    } catch (error) {
      console.error('[AiProvider] completions é”™è¯¯:', error);
      
      if (onChunk) {
        await onChunk({
          type: ChunkType.ERROR,
          error: { message: error instanceof Error ? error.message : String(error) },
        });
      }

      if (params.shouldThrow !== false) {
        throw error;
      }

      return {
        getText: () => finalText,
        getReasoning: () => finalReasoning || undefined,
        usage,
      };
    }
  }

  /**
   * å¸¦ Trace çš„ Completions
   */
  public async completionsForTrace(
    params: CompletionsParams,
    options?: { signal?: AbortSignal; timeout?: number }
  ): Promise<CompletionsResult> {
    // ç®€åŒ–ç‰ˆï¼Œæš‚ä¸å®ç° trace
    return this.completions(params, options);
  }

  /**
   * è·å–æ¨¡å‹åˆ—è¡¨
   */
  public async models(): Promise<SdkModel[]> {
    await this.ensureInitialized();
    return this.apiClient.listModels();
  }

  /**
   * è·å– Embedding ç»´åº¦
   */
  public async getEmbeddingDimensions(model: Model): Promise<number> {
    await this.ensureInitialized();
    return this.apiClient.getEmbeddingDimensions(model);
  }

  /**
   * ç”Ÿæˆå›¾ç‰‡
   */
  public async generateImage(params: GenerateImageParams): Promise<string[]> {
    await this.ensureInitialized();
    return this.apiClient.generateImage(params as any);
  }

  /**
   * è·å– Base URL
   */
  public getBaseURL(): string {
    return this.provider.apiHost || '';
  }

  /**
   * è·å– API Key
   */
  public getApiKey(): string {
    return this.provider.apiKey || '';
  }

  // ==================== Private Methods ====================

  /**
   * å¤„ç† Gemini æµå¼å“åº”
   * å¯¹æ ‡ Cherry Studio getResponseChunkTransformer + TextChunkMiddleware
   * 
   * å…³é”®ï¼šTEXT_DELTA å‘é€çš„æ˜¯ç´¯ç§¯åçš„å®Œæ•´æ–‡æœ¬ï¼Œä¸æ˜¯åŸå§‹å¢é‡
   */
  private async processGeminiStream(
    rawStream: AsyncIterable<any>,
    onChunk: (chunk: Chunk) => void
  ): Promise<void> {
    let isFirstTextChunk = true;
    let isFirstThinkingChunk = true;
    let hasThinkingContent = false; // ğŸ”§ è¿½è¸ªæ˜¯å¦æœ‰æ€è€ƒå†…å®¹
    const toolCalls: any[] = [];
    
    // å¯¹æ ‡ Cherry Studio TextChunkMiddleware: ç´¯ç§¯æ–‡æœ¬
    let accumulatedTextContent = '';
    let accumulatedThinkingContent = '';

    for await (const rawChunk of rawStream) {
      // Cherry Studio: if (typeof chunk === 'string') { chunk = JSON.parse(chunk) }
      let chunk = rawChunk;
      if (typeof chunk === 'string') {
        try {
          chunk = JSON.parse(chunk);
        } catch (error) {
          console.error('[AiProvider] Gemini invalid chunk:', chunk, error);
          continue;
        }
      }

      // å¤„ç† candidates
      if (chunk.candidates && chunk.candidates.length > 0) {
        for (const candidate of chunk.candidates) {
          if (candidate.content?.parts) {
            for (const part of candidate.content.parts) {
              const text = part.text || '';

              // æ€è€ƒå†…å®¹
              if (part.thought) {
                if (isFirstThinkingChunk) {
                  onChunk({ type: ChunkType.THINKING_START });
                  isFirstThinkingChunk = false;
                }
                hasThinkingContent = true;
                // ç´¯ç§¯æ€è€ƒå†…å®¹
                accumulatedThinkingContent += text;
                onChunk({ 
                  type: ChunkType.THINKING_DELTA, 
                  text: accumulatedThinkingContent  // å‘é€ç´¯ç§¯åçš„å®Œæ•´æ–‡æœ¬
                } as Chunk);
              }
              // æ™®é€šæ–‡æœ¬
              else if (part.text) {
                // ğŸ”§ ä¿®å¤ï¼šæ€è€ƒç»“æŸåå‘é€ THINKING_COMPLETE
                if (hasThinkingContent && isFirstTextChunk) {
                  onChunk({ 
                    type: ChunkType.THINKING_COMPLETE,
                    text: accumulatedThinkingContent,
                  } as Chunk);
                  hasThinkingContent = false;
                }
                if (isFirstTextChunk) {
                  onChunk({ type: ChunkType.TEXT_START });
                  isFirstTextChunk = false;
                }
                // å¯¹æ ‡ Cherry Studio TextChunkMiddleware: accumulatedTextContent += chunk.text
                accumulatedTextContent += text;
                onChunk({ 
                  type: ChunkType.TEXT_DELTA, 
                  text: accumulatedTextContent  // å‘é€ç´¯ç§¯åçš„å®Œæ•´æ–‡æœ¬ï¼
                } as Chunk);
              }
              // å›¾ç‰‡
              else if (part.inlineData) {
                const imageData = part.inlineData.data?.startsWith('data:')
                  ? part.inlineData.data
                  : `data:${part.inlineData.mimeType || 'image/png'};base64,${part.inlineData.data}`;
                onChunk({
                  type: ChunkType.IMAGE_COMPLETE,
                  image: { type: 'base64', images: [imageData] },
                } as Chunk);
              }
              // å·¥å…·è°ƒç”¨
              else if (part.functionCall) {
                toolCalls.push(part.functionCall);
              }
            }
          }

          // å®Œæˆå¤„ç†
          if (candidate.finishReason) {
            // ğŸ”§ ä¿®å¤ï¼šç¡®ä¿æ€è€ƒå®Œæˆäº‹ä»¶è¢«å‘é€
            if (hasThinkingContent) {
              onChunk({ 
                type: ChunkType.THINKING_COMPLETE,
                text: accumulatedThinkingContent,
              } as Chunk);
              hasThinkingContent = false;
            }

            // æœç´¢ç»“æœ
            if (candidate.groundingMetadata) {
              onChunk({
                type: ChunkType.LLM_WEB_SEARCH_COMPLETE,
                llm_web_search: {
                  results: candidate.groundingMetadata,
                  source: 'gemini',
                },
              } as unknown as Chunk);
            }

            // å·¥å…·è°ƒç”¨
            if (toolCalls.length > 0) {
              onChunk({
                type: ChunkType.MCP_TOOL_CREATED,
                tool_calls: [...toolCalls],
              } as unknown as Chunk);
              toolCalls.length = 0;
            }

            // å‘é€ TEXT_COMPLETEï¼ˆå¯¹æ ‡ Cherry Studioï¼‰
            if (accumulatedTextContent) {
              onChunk({
                type: ChunkType.TEXT_COMPLETE,
                text: accumulatedTextContent,
              } as Chunk);
            }

            // å“åº”å®Œæˆ
            onChunk({
              type: ChunkType.LLM_RESPONSE_COMPLETE,
              response: {
                usage: {
                  prompt_tokens: chunk.usageMetadata?.promptTokenCount || 0,
                  completion_tokens: (chunk.usageMetadata?.totalTokenCount || 0) - (chunk.usageMetadata?.promptTokenCount || 0),
                  total_tokens: chunk.usageMetadata?.totalTokenCount || 0,
                },
              },
            });
          }
        }
      }
    }
  }

  /**
   * åˆ¤æ–­æ˜¯å¦ä¸ºä¸“ç”¨å›¾ç‰‡ç”Ÿæˆæ¨¡å‹
   * å¯¹æ ‡ Cherry Studio isDedicatedImageGenerationModel
   */
  private isDedicatedImageGenerationModel(model: Model): boolean {
    const modelId = model.id.toLowerCase();
    
    // DALL-E ç³»åˆ—
    if (modelId.includes('dall-e')) return true;
    
    // Stable Diffusion
    if (modelId.includes('stable-diffusion')) return true;
    if (modelId.includes('sdxl')) return true;
    
    // Midjourney
    if (modelId.includes('midjourney')) return true;
    
    // Imagen (Google)
    if (modelId.includes('imagen')) return true;
    
    // Flux
    if (modelId.includes('flux')) return true;
    
    // é€šç”¨å›¾ç‰‡ç”Ÿæˆæ¨¡å‹æ ‡è¯†
    if (modelId.includes('image-generation')) return true;
    if (modelId.includes('text-to-image')) return true;
    
    // æ£€æŸ¥æ¨¡å‹èƒ½åŠ›
    if ((model as any).capabilities?.imageGeneration === true) return true;
    if ((model as any).type === 'image') return true;
    
    return false;
  }

  /**
   * è½¬æ¢æ¶ˆæ¯æ ¼å¼
   * ğŸ”§ æ”¯æŒ MCP æç¤ºè¯æ³¨å…¥æ¨¡å¼
   */
  private transformMessages(
    messages: Message[] | string,
    assistant: Assistant,
    mcpTools?: MCPTool[],
    mcpMode?: 'prompt' | 'function'
  ): Message[] {
    // å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºæ¶ˆæ¯æ•°ç»„
    if (typeof messages === 'string') {
      return [{ role: 'user', content: messages }];
    }

    // æ„å»ºç³»ç»Ÿæç¤ºè¯
    let systemPrompt = assistant.prompt || '';

    // ğŸ”§ å…³é”®ï¼šå¦‚æœæœ‰ MCP å·¥å…·ä¸”ä½¿ç”¨æç¤ºè¯æ³¨å…¥æ¨¡å¼ï¼Œæ³¨å…¥å·¥å…·å®šä¹‰
    console.log(`[AiProvider] MCP çŠ¶æ€ - å·¥å…·æ•°é‡: ${mcpTools?.length || 0}, æ¨¡å¼: ${mcpMode}`);
    
    if (mcpTools && mcpTools.length > 0 && mcpMode === 'prompt') {
      console.log(`[AiProvider] ğŸ”§ æç¤ºè¯æ³¨å…¥æ¨¡å¼ï¼šæ³¨å…¥ ${mcpTools.length} ä¸ª MCP å·¥å…·`);
      systemPrompt = buildSystemPrompt(systemPrompt, mcpTools as any);
      console.log(`[AiProvider] æ³¨å…¥åç³»ç»Ÿæç¤ºè¯é•¿åº¦: ${systemPrompt.length}`);
    } else if (mcpTools && mcpTools.length > 0) {
      console.log(`[AiProvider] å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼š${mcpTools.length} ä¸ªå·¥å…·å°†é€šè¿‡ tools å‚æ•°ä¼ é€’`);
    }

    // æ·»åŠ ç³»ç»Ÿæç¤ºè¯
    const result: Message[] = [];
    if (systemPrompt) {
      result.push({ role: 'system', content: systemPrompt });
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    result.push(...messages);
    return result;
  }

  // ==================== V2: ä½¿ç”¨æ–°ä¸­é—´ä»¶ç³»ç»Ÿ ====================

  /**
   * æ‰§è¡Œ Completions è¯·æ±‚ï¼ˆV2 - ä½¿ç”¨æ–°ä¸­é—´ä»¶ç³»ç»Ÿï¼‰
   * åŸºäº Redux é£æ ¼ä¸­é—´ä»¶æ¶æ„ï¼Œå¯¹æ ‡ Cherry Studio
   */
  public async completionsV2(
    params: CompletionsParams,
    options?: { signal?: AbortSignal; timeout?: number }
  ): Promise<CompletionsResult> {
    await this.ensureInitialized();

    const { messages, assistant, onChunk, mcpTools, mcpMode } = params;
    const model = assistant.model;

    console.log('[AiProvider.V2] ä½¿ç”¨æ–°ä¸­é—´ä»¶ç³»ç»Ÿæ‰§è¡Œ completions');

    // 1. è½¬æ¢æ¶ˆæ¯æ ¼å¼
    const sdkMessages = this.transformMessages(messages, assistant, mcpTools, mcpMode);

    // 2. æ„å»ºä¸­é—´ä»¶é“¾ï¼ˆå¯¹æ ‡ Cherry Studioï¼‰
    const builder = CompletionsMiddlewareBuilder.withDefaults();
    
    // ğŸ”§ å›¾ç‰‡ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨ä¸“ç”¨ä¸­é—´ä»¶é“¾ï¼ˆå¯¹æ ‡ Cherry Studioï¼‰
    if (model && this.isDedicatedImageGenerationModel(model)) {
      console.log('[AiProvider.V2] æ£€æµ‹åˆ°å›¾ç‰‡ç”Ÿæˆæ¨¡å‹ï¼Œä½¿ç”¨ä¸“ç”¨ä¸­é—´ä»¶é“¾');
      builder.clear();
      builder
        .add(MiddlewareRegistry[FinalChunkConsumerMiddlewareName])
        .add(MiddlewareRegistry[ErrorHandlerMiddlewareName])
        .add(MiddlewareRegistry[AbortHandlerMiddlewareName])
        .add(MiddlewareRegistry[ImageGenerationMiddlewareName]);
    } else {
      // æ™®é€šå¯¹è¯æ¨¡å‹ï¼šæ ¹æ®é…ç½®è°ƒæ•´ä¸­é—´ä»¶
      if (!mcpTools?.length) {
        builder.remove('McpToolChunkMiddleware');
        builder.remove('ToolUseExtractionMiddleware');
      }
      if (!params.enableWebSearch) {
        builder.remove('WebSearchMiddleware');
      }
    }

    const middlewareNames = builder.getNames();
    const middlewares = builder.build();
    console.log(`[AiProvider.V2] ä¸­é—´ä»¶é“¾: ${middlewareNames.join(' â†’ ')}`);

    // 3. æ„å»ºä¸­é—´ä»¶å‚æ•°
    const middlewareParams: MiddlewareCompletionsParams = {
      callType: params.callType,
      messages: sdkMessages.map((m, i) => ({
        id: m.id || `msg-${i}`,
        role: m.role,
        content: m.content,
      })) as any,
      assistant: {
        id: assistant.id,
        name: assistant.name,
        prompt: assistant.prompt,
        model: assistant.model,
        settings: {
          temperature: assistant.settings?.temperature,
          topP: assistant.settings?.topP,
          maxTokens: assistant.settings?.maxTokens || params.maxTokens,
          streamOutput: params.streamOutput !== false,
        },
      },
      streamOutput: params.streamOutput !== false,
      topicId: params.topicId,
      mcpTools: mcpTools?.map(t => ({
        ...t,
        serverName: t.serverId || 'unknown',
        serverId: t.serverId || 'unknown',
      })) as any,
      mcpMode: mcpMode || 'function',
      enableToolUse: !!mcpTools?.length,
      enableWebSearch: params.enableWebSearch,
      enableGenerateImage: params.enableGenerateImage,
      maxTokens: params.maxTokens || assistant.settings?.maxTokens,
      onChunk: onChunk as any,
      abortSignal: options?.signal || params.abortSignal,
      shouldThrow: params.shouldThrow,
    };

    // 4. åº”ç”¨ä¸­é—´ä»¶å¹¶æ‰§è¡Œ
    const enhancedCompletions = applyCompletionsMiddlewares(
      this.apiClient as any,
      this.apiClient.createCompletions.bind(this.apiClient),
      middlewares
    );

    try {
      const result = await enhancedCompletions(middlewareParams, {
        signal: options?.signal || params.abortSignal,
      });

      console.log('[AiProvider.V2] completions å®Œæˆ');

      return {
        getText: () => result.getText?.() || '',
        getReasoning: () => result.getReasoning?.(),
        usage: result.usage,
        rawOutput: result.rawOutput,
      };
    } catch (error) {
      console.error('[AiProvider.V2] completions é”™è¯¯:', error);
      
      if (params.shouldThrow !== false) {
        throw error;
      }

      return {
        getText: () => '',
        getReasoning: () => undefined,
      };
    }
  }
}

// ==================== Helper Functions ====================

/**
 * ä» Model åˆ›å»º Provider
 */
export function modelToProvider(model: Model): Provider {
  return {
    id: model.provider || 'custom',
    type: (model.providerType || model.provider || 'openai') as any,
    name: model.name || model.id,
    apiKey: model.apiKey || '',
    apiHost: model.baseUrl || '',
    models: [],
    enabled: true,
  };
}

/**
 * åˆ›å»º AiProvider å®ä¾‹ï¼ˆä» Modelï¼‰
 */
export function createAiProviderFromModel(model: Model): AiProvider {
  const provider = modelToProvider(model);
  return new AiProvider(provider);
}
