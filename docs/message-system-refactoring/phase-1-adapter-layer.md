# Phase 1: é€‚é…å™¨å±‚é‡æ„

> **ä¼˜å…ˆçº§**ï¼šP0 (å¿…é¡»)  
> **é¢„è®¡å·¥æ—¶**ï¼š2-3å¤©  
> **ä¾èµ–**ï¼šæ— 

## ğŸ¯ ç›®æ ‡

åˆ›å»ºç»Ÿä¸€çš„ SDK åˆ° Chunk é€‚é…å™¨å±‚ï¼Œä½¿æ‰€æœ‰ Provider é€šè¿‡åŒä¸€æ¥å£å‘é€æ ‡å‡†åŒ–çš„ Chunk äº‹ä»¶ã€‚

---

## ğŸ“‹ å½“å‰é—®é¢˜

### é—®é¢˜æè¿°
æ¯ä¸ª Provider ç›´æ¥æ„å»ºå’Œå‘é€ Chunkï¼Œå¯¼è‡´ï¼š
1. å®ç°ä¸ä¸€è‡´ï¼ˆOpenAIã€Geminiã€Anthropic å„è‡ªå¤„ç†ï¼‰
2. æ–°å¢ Provider éœ€è¦é‡å¤å®ç°æµå¤„ç†é€»è¾‘
3. æ— æ³•ç»Ÿä¸€å¤„ç† SDK ç‰¹å®šçš„äº‹ä»¶æ ¼å¼

### å½“å‰ä»£ç ç¤ºä¾‹
```typescript
// OpenAIClient.ts - ç›´æ¥æ„å»º Chunk
for await (const chunk of stream) {
  if (chunk.choices[0]?.delta?.content) {
    onChunk({
      type: ChunkType.TEXT_DELTA,
      text: chunk.choices[0].delta.content
    })
  }
}

// GeminiClient.ts - å¦ä¸€ç§å®ç°
for await (const chunk of stream) {
  const text = chunk.text()
  onChunk({
    type: ChunkType.TEXT_DELTA,
    text: text
  })
}
```

---

## ğŸ—ï¸ ç›®æ ‡æ¶æ„

### Cherry Studio å‚è€ƒ
```typescript
// AiSdkToChunkAdapter.ts
export class AiSdkToChunkAdapter {
  constructor(
    private onChunk: (chunk: Chunk) => void,
    mcpTools: MCPTool[] = [],
    accumulate?: boolean,
    enableWebSearch?: boolean
  ) {}

  async processStream(aiSdkResult: any): Promise<string> {
    if (aiSdkResult.fullStream) {
      await this.readFullStream(aiSdkResult.fullStream)
    }
    return await aiSdkResult.text
  }

  private convertAndEmitChunk(chunk: TextStreamPart) {
    switch (chunk.type) {
      case 'text-start':
        this.onChunk({ type: ChunkType.TEXT_START })
        break
      case 'text-delta':
        this.onChunk({ type: ChunkType.TEXT_DELTA, text: chunk.text })
        break
      // ...
    }
  }
}
```

### AetherLink ç›®æ ‡ç»“æ„
```
src/shared/aiCore/adapters/
â”œâ”€â”€ index.ts                    # å¯¼å‡ºå…¥å£
â”œâ”€â”€ BaseChunkAdapter.ts         # æŠ½è±¡åŸºç±»
â”œâ”€â”€ OpenAIChunkAdapter.ts       # OpenAI é€‚é…å™¨
â”œâ”€â”€ GeminiChunkAdapter.ts       # Gemini é€‚é…å™¨
â”œâ”€â”€ AnthropicChunkAdapter.ts    # Anthropic é€‚é…å™¨
â””â”€â”€ types.ts                    # é€‚é…å™¨ç±»å‹å®šä¹‰
```

---

## ğŸ“ è¯¦ç»†ä»»åŠ¡

### Task 1.1: åˆ›å»ºé€‚é…å™¨æ¥å£å’ŒåŸºç±»

**æ–‡ä»¶**ï¼š`src/shared/aiCore/adapters/types.ts`

```typescript
import type { Chunk } from '../../types/chunk';
import type { MCPTool } from '../../types';

/**
 * Chunk é€‚é…å™¨é…ç½®
 */
export interface ChunkAdapterConfig {
  /** Chunk å›è°ƒå‡½æ•° */
  onChunk: (chunk: Chunk) => void;
  /** MCP å·¥å…·åˆ—è¡¨ */
  mcpTools?: MCPTool[];
  /** æ˜¯å¦ç´¯ç§¯æ–‡æœ¬ï¼ˆtrue=ç´¯ç§¯æ¨¡å¼ï¼Œfalse=å¢é‡æ¨¡å¼ï¼‰*/
  accumulate?: boolean;
  /** æ˜¯å¦å¯ç”¨ Web æœç´¢ */
  enableWebSearch?: boolean;
  /** ä¼šè¯æ›´æ–°å›è°ƒ */
  onSessionUpdate?: (sessionId: string) => void;
}

/**
 * æµå¤„ç†ç»“æœ
 */
export interface StreamProcessResult {
  /** æœ€ç»ˆæ–‡æœ¬å†…å®¹ */
  text: string;
  /** æ¨ç†å†…å®¹ */
  reasoning?: string;
  /** ä½¿ç”¨ç»Ÿè®¡ */
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * Chunk é€‚é…å™¨æ¥å£
 */
export interface IChunkAdapter {
  /**
   * å¤„ç†æµå¼å“åº”
   * @param stream åŸå§‹æµ
   * @returns å¤„ç†ç»“æœ
   */
  processStream(stream: any): Promise<StreamProcessResult>;
  
  /**
   * å¤„ç†éæµå¼å“åº”
   * @param response å®Œæ•´å“åº”
   * @returns å¤„ç†ç»“æœ
   */
  processResponse?(response: any): Promise<StreamProcessResult>;
}
```

**æ–‡ä»¶**ï¼š`src/shared/aiCore/adapters/BaseChunkAdapter.ts`

```typescript
import type { Chunk } from '../../types/chunk';
import { ChunkType } from '../../types/chunk';
import type { ChunkAdapterConfig, IChunkAdapter, StreamProcessResult } from './types';

/**
 * Chunk é€‚é…å™¨åŸºç±»
 * æä¾›é€šç”¨çš„æµå¤„ç†é€»è¾‘å’ŒçŠ¶æ€ç®¡ç†
 */
export abstract class BaseChunkAdapter implements IChunkAdapter {
  protected config: ChunkAdapterConfig;
  protected accumulatedText = '';
  protected accumulatedReasoning = '';
  protected isFirstChunk = true;
  protected responseStartTime: number | null = null;
  protected firstTokenTime: number | null = null;

  constructor(config: ChunkAdapterConfig) {
    this.config = config;
  }

  /**
   * å‘é€ Chunk äº‹ä»¶
   */
  protected emit(chunk: Chunk): void {
    this.config.onChunk(chunk);
  }

  /**
   * å‘é€æ–‡æœ¬å¼€å§‹äº‹ä»¶
   */
  protected emitTextStart(): void {
    this.emit({ type: ChunkType.TEXT_START });
  }

  /**
   * å‘é€æ–‡æœ¬å¢é‡äº‹ä»¶
   */
  protected emitTextDelta(text: string): void {
    if (!text) return;
    
    if (this.config.accumulate) {
      this.accumulatedText += text;
      this.emit({ type: ChunkType.TEXT_DELTA, text: this.accumulatedText });
    } else {
      this.accumulatedText += text;
      this.emit({ type: ChunkType.TEXT_DELTA, text });
    }
    
    this.markFirstToken();
  }

  /**
   * å‘é€æ–‡æœ¬å®Œæˆäº‹ä»¶
   */
  protected emitTextComplete(text?: string): void {
    const finalText = text ?? this.accumulatedText;
    this.emit({ type: ChunkType.TEXT_COMPLETE, text: finalText });
  }

  /**
   * å‘é€æ€è€ƒå¼€å§‹äº‹ä»¶
   */
  protected emitThinkingStart(): void {
    this.emit({ type: ChunkType.THINKING_START });
  }

  /**
   * å‘é€æ€è€ƒå¢é‡äº‹ä»¶
   */
  protected emitThinkingDelta(text: string, thinkingMillsec?: number): void {
    if (!text) return;
    this.accumulatedReasoning = text; // æ€è€ƒå†…å®¹é€šå¸¸æ˜¯ç´¯ç§¯çš„
    this.emit({ 
      type: ChunkType.THINKING_DELTA, 
      text: this.accumulatedReasoning,
      thinking_millsec: thinkingMillsec 
    });
    this.markFirstToken();
  }

  /**
   * å‘é€æ€è€ƒå®Œæˆäº‹ä»¶
   */
  protected emitThinkingComplete(text?: string, thinkingMillsec?: number): void {
    const finalText = text ?? this.accumulatedReasoning;
    this.emit({ 
      type: ChunkType.THINKING_COMPLETE, 
      text: finalText,
      thinking_millsec: thinkingMillsec
    });
  }

  /**
   * å‘é€é”™è¯¯äº‹ä»¶
   */
  protected emitError(error: Error | string): void {
    const errorObj = typeof error === 'string' ? new Error(error) : error;
    this.emit({ 
      type: ChunkType.ERROR, 
      error: { message: errorObj.message } 
    });
  }

  /**
   * å‘é€å—å®Œæˆäº‹ä»¶
   */
  protected emitBlockComplete(response?: any): void {
    this.emit({ 
      type: ChunkType.BLOCK_COMPLETE,
      response 
    });
  }

  /**
   * å‘é€ LLM å“åº”åˆ›å»ºäº‹ä»¶
   */
  protected emitLLMResponseCreated(): void {
    this.emit({ type: ChunkType.LLM_RESPONSE_CREATED });
  }

  /**
   * å‘é€ LLM å“åº”å®Œæˆäº‹ä»¶
   */
  protected emitLLMResponseComplete(response?: any): void {
    this.emit({ type: ChunkType.LLM_RESPONSE_COMPLETE, response });
  }

  /**
   * æ ‡è®°å“åº”å¼€å§‹æ—¶é—´
   */
  protected markResponseStart(): void {
    this.responseStartTime = Date.now();
  }

  /**
   * æ ‡è®°é¦–ä¸ª token æ—¶é—´
   */
  protected markFirstToken(): void {
    if (this.firstTokenTime === null && this.responseStartTime !== null) {
      this.firstTokenTime = Date.now();
    }
  }

  /**
   * æ„å»ºæ€§èƒ½æŒ‡æ ‡
   */
  protected buildMetrics(completionTokens: number = 0): any {
    const now = Date.now();
    const start = this.responseStartTime ?? now;
    const firstToken = this.firstTokenTime;
    
    return {
      completion_tokens: completionTokens,
      time_first_token_millsec: firstToken ? firstToken - start : 0,
      time_completion_millsec: now - start
    };
  }

  /**
   * é‡ç½®çŠ¶æ€
   */
  protected reset(): void {
    this.accumulatedText = '';
    this.accumulatedReasoning = '';
    this.isFirstChunk = true;
    this.responseStartTime = null;
    this.firstTokenTime = null;
  }

  /**
   * å­ç±»å®ç°ï¼šå¤„ç†æµå¼å“åº”
   */
  abstract processStream(stream: any): Promise<StreamProcessResult>;
}
```

---

### Task 1.2: å®ç° OpenAI é€‚é…å™¨

**æ–‡ä»¶**ï¼š`src/shared/aiCore/adapters/OpenAIChunkAdapter.ts`

```typescript
import { ChunkType } from '../../types/chunk';
import { BaseChunkAdapter } from './BaseChunkAdapter';
import type { ChunkAdapterConfig, StreamProcessResult } from './types';

/**
 * OpenAI æµå¼å“åº” Chunk ç±»å‹
 */
interface OpenAIStreamChunk {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    delta: {
      role?: string;
      content?: string;
      reasoning_content?: string;
      tool_calls?: Array<{
        index: number;
        id?: string;
        type?: string;
        function?: {
          name?: string;
          arguments?: string;
        };
      }>;
    };
    finish_reason: string | null;
  }>;
  usage?: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * OpenAI Chunk é€‚é…å™¨
 * å°† OpenAI SDK çš„æµå¼å“åº”è½¬æ¢ä¸ºæ ‡å‡† Chunk æ ¼å¼
 */
export class OpenAIChunkAdapter extends BaseChunkAdapter {
  private hasEmittedTextStart = false;
  private hasEmittedThinkingStart = false;
  private toolCallsBuffer: Map<number, any> = new Map();

  constructor(config: ChunkAdapterConfig) {
    super(config);
  }

  async processStream(stream: AsyncIterable<OpenAIStreamChunk>): Promise<StreamProcessResult> {
    this.reset();
    this.markResponseStart();
    this.emitLLMResponseCreated();

    let usage: StreamProcessResult['usage'];

    try {
      for await (const chunk of stream) {
        this.processChunk(chunk);
        
        if (chunk.usage) {
          usage = chunk.usage;
        }
      }

      // å‘é€å®Œæˆäº‹ä»¶
      if (this.accumulatedText) {
        this.emitTextComplete();
      }
      if (this.accumulatedReasoning) {
        this.emitThinkingComplete();
      }

      const response = {
        text: this.accumulatedText,
        reasoning_content: this.accumulatedReasoning,
        usage,
        metrics: this.buildMetrics(usage?.completion_tokens)
      };

      this.emitBlockComplete(response);
      this.emitLLMResponseComplete(response);

      return {
        text: this.accumulatedText,
        reasoning: this.accumulatedReasoning,
        usage
      };
    } catch (error) {
      this.emitError(error as Error);
      throw error;
    }
  }

  private processChunk(chunk: OpenAIStreamChunk): void {
    const choice = chunk.choices[0];
    if (!choice) return;

    const delta = choice.delta;

    // å¤„ç†æ€è€ƒå†…å®¹ (reasoning_content)
    if (delta.reasoning_content) {
      if (!this.hasEmittedThinkingStart) {
        this.emitThinkingStart();
        this.hasEmittedThinkingStart = true;
      }
      this.emitThinkingDelta(delta.reasoning_content);
    }

    // å¤„ç†æ–‡æœ¬å†…å®¹
    if (delta.content) {
      if (!this.hasEmittedTextStart) {
        // å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œå…ˆå®Œæˆæ€è€ƒ
        if (this.hasEmittedThinkingStart && this.accumulatedReasoning) {
          this.emitThinkingComplete();
        }
        this.emitTextStart();
        this.hasEmittedTextStart = true;
      }
      this.emitTextDelta(delta.content);
    }

    // å¤„ç†å·¥å…·è°ƒç”¨
    if (delta.tool_calls) {
      this.processToolCalls(delta.tool_calls);
    }

    // å¤„ç†ç»“æŸåŸå› 
    if (choice.finish_reason) {
      this.handleFinishReason(choice.finish_reason);
    }
  }

  private processToolCalls(toolCalls: NonNullable<OpenAIStreamChunk['choices'][0]['delta']['tool_calls']>): void {
    for (const tc of toolCalls) {
      let existing = this.toolCallsBuffer.get(tc.index);
      
      if (!existing) {
        existing = {
          id: tc.id || '',
          type: tc.type || 'function',
          function: { name: '', arguments: '' }
        };
        this.toolCallsBuffer.set(tc.index, existing);
      }

      if (tc.id) existing.id = tc.id;
      if (tc.function?.name) existing.function.name += tc.function.name;
      if (tc.function?.arguments) existing.function.arguments += tc.function.arguments;
    }
  }

  private handleFinishReason(reason: string): void {
    if (reason === 'tool_calls') {
      // å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
      const toolCalls = Array.from(this.toolCallsBuffer.values());
      if (toolCalls.length > 0) {
        this.emit({
          type: ChunkType.MCP_TOOL_IN_PROGRESS,
          responses: toolCalls.map(tc => ({
            id: tc.id,
            name: tc.function.name,
            arguments: JSON.parse(tc.function.arguments || '{}'),
            status: 'pending'
          }))
        });
      }
    }
  }

  protected reset(): void {
    super.reset();
    this.hasEmittedTextStart = false;
    this.hasEmittedThinkingStart = false;
    this.toolCallsBuffer.clear();
  }
}
```

---

### Task 1.3: å®ç° Gemini é€‚é…å™¨

**æ–‡ä»¶**ï¼š`src/shared/aiCore/adapters/GeminiChunkAdapter.ts`

```typescript
import { BaseChunkAdapter } from './BaseChunkAdapter';
import type { ChunkAdapterConfig, StreamProcessResult } from './types';

/**
 * Gemini Chunk é€‚é…å™¨
 */
export class GeminiChunkAdapter extends BaseChunkAdapter {
  private hasEmittedTextStart = false;
  private hasEmittedThinkingStart = false;

  constructor(config: ChunkAdapterConfig) {
    super(config);
  }

  async processStream(stream: AsyncIterable<any>): Promise<StreamProcessResult> {
    this.reset();
    this.markResponseStart();
    this.emitLLMResponseCreated();

    try {
      for await (const chunk of stream) {
        this.processChunk(chunk);
      }

      // å‘é€å®Œæˆäº‹ä»¶
      if (this.accumulatedText) {
        this.emitTextComplete();
      }
      if (this.accumulatedReasoning) {
        this.emitThinkingComplete();
      }

      const response = {
        text: this.accumulatedText,
        reasoning_content: this.accumulatedReasoning,
        metrics: this.buildMetrics()
      };

      this.emitBlockComplete(response);
      this.emitLLMResponseComplete(response);

      return {
        text: this.accumulatedText,
        reasoning: this.accumulatedReasoning
      };
    } catch (error) {
      this.emitError(error as Error);
      throw error;
    }
  }

  private processChunk(chunk: any): void {
    // Gemini çš„å“åº”æ ¼å¼
    const text = chunk.text?.() || chunk.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (text) {
      if (!this.hasEmittedTextStart) {
        this.emitTextStart();
        this.hasEmittedTextStart = true;
      }
      this.emitTextDelta(text);
    }

    // å¤„ç†æ€è€ƒå†…å®¹ï¼ˆå¦‚æœ Gemini æ”¯æŒï¼‰
    const thought = chunk.candidates?.[0]?.content?.parts?.find((p: any) => p.thought)?.thought;
    if (thought) {
      if (!this.hasEmittedThinkingStart) {
        this.emitThinkingStart();
        this.hasEmittedThinkingStart = true;
      }
      this.emitThinkingDelta(thought);
    }

    // å¤„ç†å‡½æ•°è°ƒç”¨
    const functionCall = chunk.candidates?.[0]?.content?.parts?.find((p: any) => p.functionCall);
    if (functionCall) {
      this.processFunctionCall(functionCall.functionCall);
    }
  }

  private processFunctionCall(fc: { name: string; args: any }): void {
    this.emit({
      type: 'mcp_tool_in_progress' as any,
      responses: [{
        id: `fc_${Date.now()}`,
        name: fc.name,
        arguments: fc.args,
        status: 'pending'
      }]
    });
  }

  protected reset(): void {
    super.reset();
    this.hasEmittedTextStart = false;
    this.hasEmittedThinkingStart = false;
  }
}
```

---

### Task 1.4: åˆ›å»ºé€‚é…å™¨å·¥å‚

**æ–‡ä»¶**ï¼š`src/shared/aiCore/adapters/index.ts`

```typescript
import { OpenAIChunkAdapter } from './OpenAIChunkAdapter';
import { GeminiChunkAdapter } from './GeminiChunkAdapter';
import type { ChunkAdapterConfig, IChunkAdapter } from './types';

export * from './types';
export * from './BaseChunkAdapter';
export * from './OpenAIChunkAdapter';
export * from './GeminiChunkAdapter';

/**
 * Provider ç±»å‹
 */
export type ProviderType = 'openai' | 'gemini' | 'anthropic' | 'ollama' | 'openrouter';

/**
 * åˆ›å»º Chunk é€‚é…å™¨
 * @param providerType Provider ç±»å‹
 * @param config é€‚é…å™¨é…ç½®
 * @returns Chunk é€‚é…å™¨å®ä¾‹
 */
export function createChunkAdapter(
  providerType: ProviderType,
  config: ChunkAdapterConfig
): IChunkAdapter {
  switch (providerType) {
    case 'openai':
    case 'ollama':
    case 'openrouter':
      return new OpenAIChunkAdapter(config);
    
    case 'gemini':
      return new GeminiChunkAdapter(config);
    
    case 'anthropic':
      // Anthropic ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼
      return new OpenAIChunkAdapter(config);
    
    default:
      console.warn(`[ChunkAdapter] æœªçŸ¥çš„ Provider ç±»å‹: ${providerType}ï¼Œä½¿ç”¨ OpenAI é€‚é…å™¨`);
      return new OpenAIChunkAdapter(config);
  }
}
```

---

### Task 1.5: é›†æˆåˆ° Provider

**ä¿®æ”¹æ–‡ä»¶**ï¼š`src/shared/services/messages/ApiProvider.ts`

```typescript
// æ·»åŠ å¯¼å…¥
import { createChunkAdapter, type ChunkAdapterConfig } from '../../aiCore/adapters';

// ä¿®æ”¹ sendChatMessage æ–¹æ³•
async sendChatMessage(messages: any[], options: SendOptions): Promise<any> {
  const { onChunk, enableTools, mcpTools, abortSignal } = options;
  
  // åˆ›å»ºé€‚é…å™¨
  const adapterConfig: ChunkAdapterConfig = {
    onChunk,
    mcpTools,
    accumulate: this.model.supported_text_delta !== false
  };
  
  const adapter = createChunkAdapter(this.getProviderType(), adapterConfig);
  
  // è·å–åŸå§‹æµ
  const stream = await this.client.createChatCompletion(messages, {
    stream: true,
    signal: abortSignal
  });
  
  // ä½¿ç”¨é€‚é…å™¨å¤„ç†æµ
  const result = await adapter.processStream(stream);
  
  return {
    content: result.text,
    reasoning: result.reasoning,
    usage: result.usage
  };
}
```

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] OpenAI æµå¼å“åº”æ­£ç¡®è½¬æ¢ä¸º Chunk
- [ ] Gemini æµå¼å“åº”æ­£ç¡®è½¬æ¢ä¸º Chunk
- [ ] æ€è€ƒå†…å®¹æ­£ç¡®å¤„ç† THINKING_START/DELTA/COMPLETE
- [ ] å·¥å…·è°ƒç”¨æ­£ç¡®è§¦å‘ MCP_TOOL_* äº‹ä»¶
- [ ] é”™è¯¯æ­£ç¡®è½¬æ¢ä¸º ERROR Chunk

### ä»£ç éªŒæ”¶
- [ ] æ‰€æœ‰é€‚é…å™¨ç»§æ‰¿ BaseChunkAdapter
- [ ] ç»Ÿä¸€ä½¿ç”¨ createChunkAdapter å·¥å‚å‡½æ•°
- [ ] æ·»åŠ å®Œæ•´çš„ TypeScript ç±»å‹å®šä¹‰
- [ ] æ·»åŠ å…³é”®è·¯å¾„æ—¥å¿—

### æµ‹è¯•éªŒæ”¶
- [ ] OpenAI æ™®é€šå¯¹è¯æµ‹è¯•é€šè¿‡
- [ ] OpenAI æ·±åº¦æ€è€ƒæµ‹è¯•é€šè¿‡
- [ ] Gemini æ™®é€šå¯¹è¯æµ‹è¯•é€šè¿‡
- [ ] å·¥å…·è°ƒç”¨æµ‹è¯•é€šè¿‡
- [ ] ä¸­æ–­/å–æ¶ˆæµ‹è¯•é€šè¿‡

---

## ğŸ“… é‡Œç¨‹ç¢‘

| æ—¥æœŸ | ä»»åŠ¡ | çŠ¶æ€ |
|------|------|------|
| Day 1 | Task 1.1-1.2: åŸºç±»å’Œ OpenAI é€‚é…å™¨ | â³ |
| Day 2 | Task 1.3-1.4: Gemini é€‚é…å™¨å’Œå·¥å‚ | â³ |
| Day 3 | Task 1.5: é›†æˆå’Œæµ‹è¯• | â³ |

---

## âš ï¸ é£é™©å’Œæ³¨æ„äº‹é¡¹

1. **å‘åå…¼å®¹**ï¼šä¿ç•™åŸæœ‰çš„ç›´æ¥ Chunk å‘é€æ–¹å¼ä½œä¸º fallback
2. **æ€§èƒ½å½±å“**ï¼šé€‚é…å™¨å±‚ä¼šå¢åŠ å°‘é‡å¼€é”€ï¼Œéœ€è¦ç›‘æ§
3. **ç‰¹æ®Šæ ¼å¼**ï¼šæŸäº› Provider å¯èƒ½æœ‰ç‰¹æ®Šçš„å“åº”æ ¼å¼ï¼Œéœ€è¦ç‰¹åˆ«å¤„ç†
