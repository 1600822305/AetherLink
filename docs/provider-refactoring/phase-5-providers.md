# Phase 5: ä¾›åº”å•†è¿ç§»

> é¢„è®¡å·¥æ—¶ï¼š5-7å¤©
> å‰ç½®ä¾èµ–ï¼šPhase 4 (ä¸­é—´ä»¶ç³»ç»Ÿ)
> å‚è€ƒæ–‡ä»¶ï¼š`cherry-studio-main/src/renderer/src/aiCore/legacy/clients/`

## ğŸ¯ ç›®æ ‡

1. å°†ç°æœ‰ä¾›åº”å•†é€ä¸ªè¿ç§»åˆ°æ–°æ¶æ„
2. å®ç°å„ä¾›åº”å•†çš„å…·ä½“å®¢æˆ·ç«¯ç±»
3. ä¿æŒå‘åå…¼å®¹ï¼Œæ”¯æŒæ¸è¿›å¼è¿ç§»
4. é…ç½®ç³»ç»Ÿä¾›åº”å•†é¢„è®¾

## ğŸ“ éœ€è¦åˆ›å»º/ä¿®æ”¹çš„æ–‡ä»¶

```
src/shared/aiCore/
â”œâ”€â”€ clients/
â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”œâ”€â”€ OpenAIClient.ts         # OpenAIå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ OpenAIResponseClient.ts # OpenAI Responses API
â”‚   â”‚   â”œâ”€â”€ transformers.ts         # è½¬æ¢å™¨
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ gemini/
â”‚   â”‚   â”œâ”€â”€ GeminiClient.ts
â”‚   â”‚   â”œâ”€â”€ transformers.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ anthropic/
â”‚   â”‚   â”œâ”€â”€ AnthropicClient.ts
â”‚   â”‚   â”œâ”€â”€ transformers.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â””â”€â”€ index.ts
â”‚
â””â”€â”€ provider/
    â””â”€â”€ configs/
        â”œâ”€â”€ system-providers.ts     # ç³»ç»Ÿä¾›åº”å•†é…ç½®
        â”œâ”€â”€ openai.ts
        â”œâ”€â”€ gemini.ts
        â””â”€â”€ index.ts
```

## ğŸ“ è¿ç§»é¡ºåº

å»ºè®®æŒ‰ä»¥ä¸‹é¡ºåºè¿ç§»ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼š

```
1. OpenAI (æœ€å¸¸ç”¨ï¼Œä½œä¸ºå‚è€ƒå®ç°)
2. OpenAI Response API (æ–°ç‰ˆAPI)
3. Anthropic (Claude)
4. Gemini (Google)
5. å…¶ä»–OpenAIå…¼å®¹ä¾›åº”å•† (DeepSeek, æ™ºè°±ç­‰)
```

## ğŸ“ è¯¦ç»†å®ç°

### 5.1 OpenAIå®¢æˆ·ç«¯ (`clients/openai/OpenAIClient.ts`)

```typescript
import OpenAI from 'openai';
import type { Provider, Model, MCPTool } from '@/shared/types';
import type { Chunk } from '../../types/chunk';
import { ChunkType } from '../../types/chunk';
import type {
  SdkRequestParams,
  SdkMessageParam,
  SdkTool,
  SdkToolCall,
  SdkModel,
  RequestOptions
} from '../../types/sdk';
import { BaseApiClient } from '../base';
import type {
  RequestTransformer,
  ResponseChunkTransformer,
  CompletionsContext,
  GenerateImageParams
} from '../base/types';

/**
 * OpenAIå®¢æˆ·ç«¯å®ç°
 * æ”¯æŒæ ‡å‡†çš„Chat Completions API
 */
export class OpenAIClient extends BaseApiClient<
  OpenAI,
  OpenAI.Chat.ChatCompletionCreateParams,
  AsyncIterable<OpenAI.Chat.ChatCompletionChunk> | OpenAI.Chat.ChatCompletion,
  OpenAI.Chat.ChatCompletionChunk,
  OpenAI.Chat.ChatCompletionMessageParam,
  OpenAI.Chat.ChatCompletionMessageToolCall,
  OpenAI.Chat.ChatCompletionTool
> {
  
  constructor(provider: Provider) {
    super(provider);
  }

  // ==================== SDKå®ä¾‹ ====================

  public getSdkInstance(): OpenAI {
    if (!this.sdkInstance) {
      this.sdkInstance = new OpenAI({
        apiKey: this.getApiKey(),
        baseURL: this.getBaseURL(),
        defaultHeaders: this.getDefaultHeaders(),
        dangerouslyAllowBrowser: true,
      });
    }
    return this.sdkInstance;
  }

  // ==================== æ ¸å¿ƒAPI ====================

  public async createCompletions(
    payload: OpenAI.Chat.ChatCompletionCreateParams,
    options?: RequestOptions
  ): Promise<AsyncIterable<OpenAI.Chat.ChatCompletionChunk> | OpenAI.Chat.ChatCompletion> {
    const sdk = this.getSdkInstance();
    
    if (payload.stream) {
      return sdk.chat.completions.create({
        ...payload,
        stream: true,
      }, {
        signal: options?.signal,
        timeout: options?.timeout,
      });
    } else {
      return sdk.chat.completions.create({
        ...payload,
        stream: false,
      }, {
        signal: options?.signal,
        timeout: options?.timeout,
      });
    }
  }

  public async listModels(): Promise<SdkModel[]> {
    const sdk = this.getSdkInstance();
    const response = await sdk.models.list();
    return response.data.map(m => ({
      id: m.id,
      object: m.object,
      created: m.created,
      owned_by: m.owned_by,
    }));
  }

  public async getEmbeddingDimensions(model?: Model): Promise<number> {
    const sdk = this.getSdkInstance();
    const response = await sdk.embeddings.create({
      model: model?.id || 'text-embedding-ada-002',
      input: 'test',
    });
    return response.data[0].embedding.length;
  }

  public async generateImage(params: GenerateImageParams): Promise<string[]> {
    const sdk = this.getSdkInstance();
    const response = await sdk.images.generate({
      model: params.model || 'dall-e-3',
      prompt: params.prompt,
      n: params.n || 1,
      size: params.size as any || '1024x1024',
      quality: params.quality as any || 'standard',
      style: params.style as any || 'natural',
    });
    return response.data.map(img => img.url || '').filter(Boolean);
  }

  // ==================== è½¬æ¢å™¨ ====================

  public getRequestTransformer(): RequestTransformer<
    OpenAI.Chat.ChatCompletionCreateParams,
    OpenAI.Chat.ChatCompletionMessageParam
  > {
    return new OpenAIRequestTransformer(this);
  }

  public getResponseChunkTransformer(
    ctx: CompletionsContext
  ): ResponseChunkTransformer<OpenAI.Chat.ChatCompletionChunk> {
    return new OpenAIResponseTransformer(ctx);
  }

  // ==================== å·¥å…·è½¬æ¢ ====================

  public convertMcpToolsToSdkTools(mcpTools: MCPTool[]): OpenAI.Chat.ChatCompletionTool[] {
    return mcpTools.map(tool => ({
      type: 'function' as const,
      function: {
        name: this.sanitizeToolName(tool.id || tool.name),
        description: tool.description || '',
        parameters: tool.inputSchema || { type: 'object', properties: {} },
      },
    }));
  }

  public convertSdkToolCallToMcp(
    toolCall: OpenAI.Chat.ChatCompletionMessageToolCall,
    mcpTools: MCPTool[]
  ): MCPTool | undefined {
    return mcpTools.find(t => 
      this.sanitizeToolName(t.id || t.name) === toolCall.function.name
    );
  }

  public convertSdkToolCallToMcpToolResponse(
    toolCall: OpenAI.Chat.ChatCompletionMessageToolCall,
    mcpTool: MCPTool
  ): any {
    return {
      id: toolCall.id,
      toolCallId: toolCall.id,
      tool: mcpTool,
      arguments: JSON.parse(toolCall.function.arguments || '{}'),
      status: 'pending' as const,
    };
  }

  public convertMcpToolResponseToSdkMessageParam(
    mcpToolResponse: any,
    resp: any,
    _model: Model
  ): OpenAI.Chat.ChatCompletionMessageParam | undefined {
    return {
      role: 'tool',
      tool_call_id: mcpToolResponse.toolCallId,
      content: resp.isError ? `Error: ${resp.content}` : resp.content,
    };
  }

  // ==================== æ¶ˆæ¯å¤„ç† ====================

  public buildSdkMessages(
    currentReqMessages: OpenAI.Chat.ChatCompletionMessageParam[],
    _output: any,
    toolResults: OpenAI.Chat.ChatCompletionMessageParam[],
    toolCalls?: OpenAI.Chat.ChatCompletionMessageToolCall[]
  ): OpenAI.Chat.ChatCompletionMessageParam[] {
    const messages = [...currentReqMessages];
    
    if (toolCalls && toolCalls.length > 0) {
      messages.push({
        role: 'assistant',
        content: null,
        tool_calls: toolCalls,
      });
    }
    
    messages.push(...toolResults);
    return messages;
  }

  public extractMessagesFromSdkPayload(
    sdkPayload: OpenAI.Chat.ChatCompletionCreateParams
  ): OpenAI.Chat.ChatCompletionMessageParam[] {
    return sdkPayload.messages;
  }

  public estimateMessageTokens(message: OpenAI.Chat.ChatCompletionMessageParam): number {
    // ç®€å•ä¼°ç®—ï¼šæ¯4ä¸ªå­—ç¬¦çº¦1ä¸ªtoken
    const content = typeof message.content === 'string' 
      ? message.content 
      : JSON.stringify(message.content);
    return Math.ceil(content.length / 4);
  }

  // ==================== è¾…åŠ©æ–¹æ³• ====================

  private sanitizeToolName(name: string): string {
    let sanitized = name;
    if (/^\d/.test(sanitized)) sanitized = `tool_${sanitized}`;
    sanitized = sanitized.replace(/[^a-zA-Z0-9_-]/g, '_');
    if (sanitized.length > 64) sanitized = sanitized.substring(0, 64);
    return sanitized;
  }

  public getClientCompatibilityType(model?: Model): string[] {
    return ['OpenAIClient', 'OpenAIAPIClient'];
  }
}

/**
 * OpenAIè¯·æ±‚è½¬æ¢å™¨
 */
class OpenAIRequestTransformer implements RequestTransformer<
  OpenAI.Chat.ChatCompletionCreateParams,
  OpenAI.Chat.ChatCompletionMessageParam
> {
  constructor(private client: OpenAIClient) {}

  transform(params: any): OpenAI.Chat.ChatCompletionCreateParams {
    const { messages, assistant, mcpTools } = params;
    const model = assistant?.model;
    
    // è½¬æ¢æ¶ˆæ¯
    const sdkMessages = messages.map((m: any) => this.transformMessage(m));
    
    // æ·»åŠ ç³»ç»Ÿæç¤ºè¯
    if (assistant?.prompt) {
      sdkMessages.unshift({
        role: 'system',
        content: assistant.prompt,
      });
    }

    // æ„å»ºè¯·æ±‚å‚æ•°
    const request: OpenAI.Chat.ChatCompletionCreateParams = {
      model: model?.id || 'gpt-3.5-turbo',
      messages: sdkMessages,
      stream: assistant?.settings?.streamOutput !== false,
      temperature: this.client['getTemperature'](assistant, model),
      top_p: this.client['getTopP'](assistant, model),
      max_tokens: this.client['getMaxTokens'](assistant, model),
    };

    // æ·»åŠ å·¥å…·
    if (mcpTools && mcpTools.length > 0) {
      const { tools } = this.client.setupToolsConfig({
        mcpTools,
        model,
        enableToolUse: true,
      });
      if (tools.length > 0) {
        request.tools = tools;
        request.tool_choice = 'auto';
      }
    }

    return request;
  }

  transformMessage(message: any): OpenAI.Chat.ChatCompletionMessageParam {
    return {
      role: message.role,
      content: typeof message.content === 'string' 
        ? message.content 
        : message.content || '',
    };
  }
}

/**
 * OpenAIå“åº”è½¬æ¢å™¨
 */
class OpenAIResponseTransformer implements ResponseChunkTransformer<OpenAI.Chat.ChatCompletionChunk> {
  constructor(private ctx: CompletionsContext) {}

  transform(chunk: OpenAI.Chat.ChatCompletionChunk): Chunk[] {
    const chunks: Chunk[] = [];
    const choice = chunk.choices[0];
    
    if (!choice) return chunks;

    // æ–‡æœ¬å†…å®¹
    if (choice.delta?.content) {
      chunks.push({
        type: ChunkType.TEXT_DELTA,
        text: choice.delta.content,
      });
    }

    // å·¥å…·è°ƒç”¨
    if (choice.delta?.tool_calls) {
      for (const toolCall of choice.delta.tool_calls) {
        if (toolCall.id) {
          chunks.push({
            type: ChunkType.MCP_TOOL_CALL_START,
            toolCallId: toolCall.id,
            toolName: toolCall.function?.name || '',
          });
        }
        if (toolCall.function?.arguments) {
          chunks.push({
            type: ChunkType.MCP_TOOL_CALL_ARGS,
            toolCallId: toolCall.id || '',
            args: toolCall.function.arguments,
          });
        }
      }
    }

    // å®ŒæˆåŸå› 
    if (choice.finish_reason === 'stop') {
      // æ–‡æœ¬å®Œæˆåœ¨FinalConsumerä¸­å¤„ç†
    }

    return chunks;
  }
}

export { OpenAIRequestTransformer, OpenAIResponseTransformer };
```

### 5.2 Geminiå®¢æˆ·ç«¯ (`clients/gemini/GeminiClient.ts`)

```typescript
import { GoogleGenAI, type Content, type Part, type Tool } from '@google/genai';
import type { Provider, Model, MCPTool } from '@/shared/types';
import type { Chunk } from '../../types/chunk';
import { ChunkType } from '../../types/chunk';
import { BaseApiClient } from '../base';
import type {
  RequestTransformer,
  ResponseChunkTransformer,
  CompletionsContext,
  GenerateImageParams
} from '../base/types';
import type { SdkModel, RequestOptions } from '../../types/sdk';

/**
 * Gemini SDKç‰¹å®šç±»å‹
 */
interface GeminiRequestParams {
  model: string;
  contents: Content[];
  systemInstruction?: string;
  generationConfig?: {
    temperature?: number;
    topP?: number;
    maxOutputTokens?: number;
  };
  tools?: Tool[];
}

/**
 * Google Geminiå®¢æˆ·ç«¯å®ç°
 */
export class GeminiClient extends BaseApiClient<
  GoogleGenAI,
  GeminiRequestParams,
  AsyncIterable<any>,
  any,
  Content,
  any,
  Tool
> {
  
  constructor(provider: Provider) {
    super(provider);
  }

  // ==================== SDKå®ä¾‹ ====================

  public getSdkInstance(): GoogleGenAI {
    if (!this.sdkInstance) {
      this.sdkInstance = new GoogleGenAI({
        apiKey: this.getApiKey(),
      });
    }
    return this.sdkInstance;
  }

  public getBaseURL(): string {
    return this.provider.apiHost || 'https://generativelanguage.googleapis.com/v1beta';
  }

  // ==================== æ ¸å¿ƒAPI ====================

  public async createCompletions(
    payload: GeminiRequestParams,
    options?: RequestOptions
  ): Promise<AsyncIterable<any>> {
    const sdk = this.getSdkInstance();
    
    const chat = sdk.chats.create({
      model: payload.model,
      config: {
        systemInstruction: payload.systemInstruction,
        ...payload.generationConfig,
        tools: payload.tools,
      },
      history: payload.contents.slice(0, -1),
    });

    const lastMessage = payload.contents[payload.contents.length - 1];
    
    return chat.sendMessageStream({
      message: lastMessage.parts as any,
      config: {
        abortSignal: options?.signal,
      },
    });
  }

  public async listModels(): Promise<SdkModel[]> {
    // Geminiéœ€è¦é€šè¿‡REST APIè·å–æ¨¡å‹åˆ—è¡¨
    const response = await fetch(`${this.getBaseURL()}/models?key=${this.getApiKey()}`);
    const data = await response.json();
    
    return (data.models || []).map((m: any) => ({
      id: m.name.replace('models/', ''),
      object: 'model',
      owned_by: 'google',
    }));
  }

  public async getEmbeddingDimensions(_model?: Model): Promise<number> {
    return 768; // Geminié»˜è®¤embeddingç»´åº¦
  }

  public async generateImage(_params: GenerateImageParams): Promise<string[]> {
    // Geminiå›¾åƒç”Ÿæˆéœ€è¦ç‰¹æ®Šå¤„ç†
    console.warn('[GeminiClient] å›¾åƒç”ŸæˆåŠŸèƒ½æš‚æœªå®ç°');
    return [];
  }

  // ==================== è½¬æ¢å™¨ ====================

  public getRequestTransformer(): RequestTransformer<GeminiRequestParams, Content> {
    return new GeminiRequestTransformer(this);
  }

  public getResponseChunkTransformer(ctx: CompletionsContext): ResponseChunkTransformer<any> {
    return new GeminiResponseTransformer(ctx);
  }

  // ==================== å·¥å…·è½¬æ¢ ====================

  public convertMcpToolsToSdkTools(mcpTools: MCPTool[]): Tool[] {
    return mcpTools.map(tool => ({
      functionDeclarations: [{
        name: this.sanitizeToolName(tool.id || tool.name),
        description: tool.description || '',
        parameters: tool.inputSchema,
      }],
    }));
  }

  public convertSdkToolCallToMcp(toolCall: any, mcpTools: MCPTool[]): MCPTool | undefined {
    return mcpTools.find(t => 
      this.sanitizeToolName(t.id || t.name) === toolCall.name
    );
  }

  public convertSdkToolCallToMcpToolResponse(toolCall: any, mcpTool: MCPTool): any {
    return {
      id: toolCall.id || `gemini_${Date.now()}`,
      toolCallId: toolCall.id,
      tool: mcpTool,
      arguments: toolCall.args || {},
      status: 'pending' as const,
    };
  }

  public convertMcpToolResponseToSdkMessageParam(
    mcpToolResponse: any,
    resp: any,
    _model: Model
  ): Content | undefined {
    return {
      role: 'user',
      parts: [{
        functionResponse: {
          name: mcpToolResponse.tool.id || mcpToolResponse.tool.name,
          response: {
            output: !resp.isError ? resp.content : undefined,
            error: resp.isError ? resp.content : undefined,
          },
        },
      }],
    };
  }

  // ==================== æ¶ˆæ¯å¤„ç† ====================

  public buildSdkMessages(
    currentReqMessages: Content[],
    _output: any,
    toolResults: Content[],
    _toolCalls?: any[]
  ): Content[] {
    return [...currentReqMessages, ...toolResults];
  }

  public extractMessagesFromSdkPayload(sdkPayload: GeminiRequestParams): Content[] {
    return sdkPayload.contents;
  }

  public estimateMessageTokens(message: Content): number {
    const text = message.parts?.map((p: Part) => p.text || '').join('') || '';
    return Math.ceil(text.length / 4);
  }

  // ==================== è¾…åŠ©æ–¹æ³• ====================

  private sanitizeToolName(name: string): string {
    let sanitized = name;
    if (/^\d/.test(sanitized)) sanitized = `mcp_${sanitized}`;
    sanitized = sanitized.replace(/[^a-zA-Z0-9_.-]/g, '_');
    if (sanitized.length > 64) sanitized = sanitized.substring(0, 64);
    if (!/^[a-zA-Z_]/.test(sanitized)) sanitized = `tool_${sanitized}`;
    return sanitized;
  }

  public getClientCompatibilityType(_model?: Model): string[] {
    return ['GeminiClient', 'GeminiAPIClient'];
  }
}

/**
 * Geminiè¯·æ±‚è½¬æ¢å™¨
 */
class GeminiRequestTransformer implements RequestTransformer<GeminiRequestParams, Content> {
  constructor(private client: GeminiClient) {}

  transform(params: any): GeminiRequestParams {
    const { messages, assistant, mcpTools } = params;
    const model = assistant?.model;

    // è½¬æ¢æ¶ˆæ¯
    const contents = messages.map((m: any) => this.transformMessage(m));

    // æ„å»ºå·¥å…·
    let tools: Tool[] = [];
    if (mcpTools && mcpTools.length > 0) {
      const config = this.client.setupToolsConfig({
        mcpTools,
        model,
        enableToolUse: true,
      });
      tools = config.tools;
    }

    return {
      model: model?.id || 'gemini-pro',
      contents,
      systemInstruction: assistant?.prompt,
      generationConfig: {
        temperature: this.client['getTemperature'](assistant, model),
        topP: this.client['getTopP'](assistant, model),
        maxOutputTokens: this.client['getMaxTokens'](assistant, model),
      },
      tools: tools.length > 0 ? tools : undefined,
    };
  }

  transformMessage(message: any): Content {
    const role = message.role === 'assistant' ? 'model' : 'user';
    return {
      role,
      parts: [{ text: message.content || '' }],
    };
  }
}

/**
 * Geminiå“åº”è½¬æ¢å™¨
 */
class GeminiResponseTransformer implements ResponseChunkTransformer<any> {
  constructor(private ctx: CompletionsContext) {}

  transform(chunk: any): Chunk[] {
    const chunks: Chunk[] = [];

    // å¤„ç†æ–‡æœ¬å†…å®¹
    if (chunk.candidates?.[0]?.content?.parts) {
      for (const part of chunk.candidates[0].content.parts) {
        if (part.thought && part.text) {
          // æ€è€ƒå†…å®¹
          chunks.push({
            type: ChunkType.THINKING_DELTA,
            text: part.text,
          });
        } else if (part.text) {
          // æ™®é€šæ–‡æœ¬
          chunks.push({
            type: ChunkType.TEXT_DELTA,
            text: part.text,
          });
        } else if (part.functionCall) {
          // å·¥å…·è°ƒç”¨
          chunks.push({
            type: ChunkType.MCP_TOOL_CALL_COMPLETE,
            toolCallId: part.functionCall.id || `fc_${Date.now()}`,
            toolName: part.functionCall.name,
            args: part.functionCall.args || {},
          });
        }
      }
    }

    return chunks;
  }
}

export { GeminiRequestTransformer, GeminiResponseTransformer };
```

### 5.3 ç³»ç»Ÿä¾›åº”å•†é…ç½® (`provider/configs/system-providers.ts`)

```typescript
import type { SystemProvider, Provider } from '../../types/provider';

/**
 * ç³»ç»Ÿå†…ç½®ä¾›åº”å•†é…ç½®
 */
export const SYSTEM_PROVIDERS_CONFIG: Record<string, SystemProvider> = {
  openai: {
    id: 'openai',
    type: 'openai-response',
    name: 'OpenAI',
    apiKey: '',
    apiHost: 'https://api.openai.com/v1',
    models: [],
    isSystem: true,
    enabled: false,
    apiOptions: {
      isSupportFunctionCalling: true,
      isSupportStreaming: true,
      isSupportMultimodal: true,
    },
  },
  
  anthropic: {
    id: 'anthropic',
    type: 'anthropic',
    name: 'Anthropic',
    apiKey: '',
    apiHost: 'https://api.anthropic.com',
    models: [],
    isSystem: true,
    enabled: false,
    apiOptions: {
      isSupportFunctionCalling: true,
      isSupportStreaming: true,
      isSupportMultimodal: true,
    },
  },
  
  gemini: {
    id: 'gemini',
    type: 'gemini',
    name: 'Google Gemini',
    apiKey: '',
    apiHost: 'https://generativelanguage.googleapis.com/v1beta',
    models: [],
    isSystem: true,
    enabled: false,
    apiOptions: {
      isSupportFunctionCalling: true,
      isSupportStreaming: true,
      isSupportMultimodal: true,
    },
  },
  
  deepseek: {
    id: 'deepseek',
    type: 'openai',
    name: 'DeepSeek',
    apiKey: '',
    apiHost: 'https://api.deepseek.com',
    models: [],
    isSystem: true,
    enabled: false,
  },
  
  zhipu: {
    id: 'zhipu',
    type: 'openai',
    name: 'æ™ºè°±AI',
    apiKey: '',
    apiHost: 'https://open.bigmodel.cn/api/paas/v4/',
    models: [],
    isSystem: true,
    enabled: false,
  },
  
  siliconflow: {
    id: 'siliconflow',
    type: 'openai',
    name: 'ç¡…åŸºæµåŠ¨',
    apiKey: '',
    apiHost: 'https://api.siliconflow.cn/v1',
    models: [],
    isSystem: true,
    enabled: false,
  },
  
  moonshot: {
    id: 'moonshot',
    type: 'openai',
    name: 'Moonshot AI',
    apiKey: '',
    apiHost: 'https://api.moonshot.cn/v1',
    models: [],
    isSystem: true,
    enabled: false,
  },
  
  ollama: {
    id: 'ollama',
    type: 'openai',
    name: 'Ollama',
    apiKey: 'ollama',
    apiHost: 'http://localhost:11434/v1',
    models: [],
    isSystem: true,
    enabled: false,
  },
};

/**
 * è·å–æ‰€æœ‰ç³»ç»Ÿä¾›åº”å•†
 */
export function getSystemProviders(): SystemProvider[] {
  return Object.values(SYSTEM_PROVIDERS_CONFIG);
}

/**
 * è·å–æŒ‡å®šä¾›åº”å•†é…ç½®
 */
export function getSystemProvider(id: string): SystemProvider | undefined {
  return SYSTEM_PROVIDERS_CONFIG[id];
}

/**
 * æ£€æŸ¥æ˜¯å¦ä¸ºç³»ç»Ÿä¾›åº”å•†
 */
export function isSystemProviderConfig(provider: Provider): boolean {
  return provider.id in SYSTEM_PROVIDERS_CONFIG && provider.isSystem === true;
}
```

## âœ… å®Œæˆæ ‡å‡†

1. [ ] OpenAIå®¢æˆ·ç«¯å®Œæˆï¼ˆæ ‡å‡†APIï¼‰
2. [ ] OpenAI Responseå®¢æˆ·ç«¯å®Œæˆï¼ˆæ–°ç‰ˆAPIï¼‰
3. [ ] Geminiå®¢æˆ·ç«¯å®Œæˆ
4. [ ] Anthropicå®¢æˆ·ç«¯å®Œæˆ
5. [ ] ç³»ç»Ÿä¾›åº”å•†é…ç½®å®Œæˆ
6. [ ] æ‰€æœ‰å®¢æˆ·ç«¯æ³¨å†Œåˆ°å·¥å‚

## ğŸ§ª æµ‹è¯•æ¸…å•

```
â–¡ OpenAIæµå¼å¯¹è¯
â–¡ OpenAIéæµå¼å¯¹è¯
â–¡ OpenAIå·¥å…·è°ƒç”¨
â–¡ Geminiæµå¼å¯¹è¯
â–¡ Geminiæ€è€ƒæ¨¡å¼
â–¡ Geminiå·¥å…·è°ƒç”¨
â–¡ Anthropicæµå¼å¯¹è¯
â–¡ é”™è¯¯å¤„ç†
â–¡ è¯·æ±‚ä¸­æ–­
```

## â¡ï¸ ä¸‹ä¸€æ­¥

å®ŒæˆPhase 5åï¼Œç»§ç»­ [Phase 6: çŠ¶æ€ç®¡ç†](./phase-6-state.md)
